{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2', bos_token='<|startoftext|>',\n",
    "                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    As her father nears the end of his life, filmm...\n",
       "1    After crossing paths at a party, a Cape Town t...\n",
       "2    To protect his family from a powerful drug lor...\n",
       "3    Feuds, flirtations and toilet talk go down amo...\n",
       "4    In a city of coaching centers known to train I...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"netflix_titles.csv\"\n",
    "titles = pd.read_csv(data_path)['description']\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length :  62\n"
     ]
    }
   ],
   "source": [
    "max_length = max([len(tokenizer.encode(title.strip())) for title in titles])\n",
    "print(\"max_length : \",max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titles, test_titles = train_test_split(titles, test_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetflixDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        for txt in txt_list:\n",
    "            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>',\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NetflixDataset(train_titles, tokenizer, max_length=max_length)\n",
    "train_size = int(0.9 * len(dataset))\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor temp in train_dataset:\\n    #print(temp[0])\\n    #print((temp[1]))\\n    \\n    #print(len(temp[0]))\\n    #print(len(temp[1]))\\n    if len(temp[0])!=len(temp[1]) and len(temp[0])==62:\\n        print(temp[0])\\n        print(temp[1])\\n    \\n        break\\n\\n    '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for temp in train_dataset:\n",
    "    #print(temp[0])\n",
    "    #print((temp[1]))\n",
    "    \n",
    "    #print(len(temp[0]))\n",
    "    #print(len(temp[1]))\n",
    "    if len(temp[0])!=len(temp[1]) and len(temp[0])==62:\n",
    "        print(temp[0])\n",
    "        print(temp[1])\n",
    "    \n",
    "        break\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./results', num_train_epochs=1, logging_steps=100, save_steps=500,\n",
    "                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "                                  warmup_steps=10, weight_decay=0.05, logging_dir='./logs', report_to = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50257, 18435,   220]], device='cuda:0')\n",
      "generated :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\transformers\\generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50257, 18435,   220,   170, 50258, 27332,   226,   229,   171,   225,\n",
      "           223,   159,   227,   235,  8582,   242,   107, 12520,   234,   230],\n",
      "        [50257, 18435,   220,   170, 50258, 27332,   226,   229,   171,   225,\n",
      "           223,   159,   227,   235,  8582,   242,   107, 12520,   234,   231]],\n",
      "       device='cuda:0')\n",
      " Hello ÔøΩ ÔÑáÔÉÅ„ÖçüîØ üåà\n"
     ]
    }
   ],
   "source": [
    "test_str = \"Hello \"\n",
    "\n",
    "generated = tokenizer(\"<|startoftext|> \"+ test_str, return_tensors=\"pt\").input_ids\n",
    "print(generated.cuda())\n",
    "print(\"generated : \",len(generated))\n",
    "sample_outputs = model.generate(generated.cuda(),no_repeat_ngram_size = 1,num_beams=20, num_return_sequences=2)\n",
    "\n",
    "print(sample_outputs)\n",
    "print(tokenizer.decode(sample_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tharh\\anaconda3\\envs\\tharhtet\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7917\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73ef3b85d1b4303972616c32d0b5856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.3517, 'learning_rate': 4.943088402681169e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2332, 'learning_rate': 4.879853294549134e-05, 'epoch': 0.03}\n",
      "{'loss': 2.1065, 'learning_rate': 4.8166181864170986e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0882, 'learning_rate': 4.753383078285064e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0953, 'learning_rate': 4.690147970153029e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2692, 'learning_rate': 4.626912862020994e-05, 'epoch': 0.08}\n",
      "{'loss': 2.123, 'learning_rate': 4.563677753888959e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0689, 'learning_rate': 4.500442645756924e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0445, 'learning_rate': 4.43720753762489e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-1000\n",
      "Configuration saved in ./results\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1044, 'learning_rate': 4.373972429492855e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-1000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0321, 'learning_rate': 4.31073732136082e-05, 'epoch': 0.14}\n",
      "{'loss': 2.0382, 'learning_rate': 4.247502213228785e-05, 'epoch': 0.15}\n",
      "{'loss': 2.0575, 'learning_rate': 4.1842671050967496e-05, 'epoch': 0.16}\n",
      "{'loss': 2.0174, 'learning_rate': 4.1210319969647146e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-1500\n",
      "Configuration saved in ./results\\checkpoint-1500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9917, 'learning_rate': 4.05779688883268e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-1500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1346, 'learning_rate': 3.994561780700645e-05, 'epoch': 0.2}\n",
      "{'loss': 2.0206, 'learning_rate': 3.93132667256861e-05, 'epoch': 0.21}\n",
      "{'loss': 2.0005, 'learning_rate': 3.868091564436576e-05, 'epoch': 0.23}\n",
      "{'loss': 2.0055, 'learning_rate': 3.80485645630454e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-2000\n",
      "Configuration saved in ./results\\checkpoint-2000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0618, 'learning_rate': 3.741621348172506e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-2000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.046, 'learning_rate': 3.678386240040471e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9627, 'learning_rate': 3.6151511319084356e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9782, 'learning_rate': 3.551916023776401e-05, 'epoch': 0.29}\n",
      "{'loss': 1.999, 'learning_rate': 3.488680915644366e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-2500\n",
      "Configuration saved in ./results\\checkpoint-2500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0476, 'learning_rate': 3.4254458075123305e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-2500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0319, 'learning_rate': 3.362210699380296e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9654, 'learning_rate': 3.298975591248261e-05, 'epoch': 0.34}\n",
      "{'loss': 2.0428, 'learning_rate': 3.235740483116226e-05, 'epoch': 0.35}\n",
      "{'loss': 1.977, 'learning_rate': 3.172505374984192e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-3000\n",
      "Configuration saved in ./results\\checkpoint-3000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9788, 'learning_rate': 3.109270266852157e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-3000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0198, 'learning_rate': 3.0460351587201213e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9844, 'learning_rate': 2.9828000505880866e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9495, 'learning_rate': 2.9195649424560516e-05, 'epoch': 0.42}\n",
      "{'loss': 2.0786, 'learning_rate': 2.856329834324017e-05, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-3500\n",
      "Configuration saved in ./results\\checkpoint-3500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0732, 'learning_rate': 2.7930947261919822e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-3500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9365, 'learning_rate': 2.729859618059947e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0852, 'learning_rate': 2.6666245099279118e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9668, 'learning_rate': 2.603389401795877e-05, 'epoch': 0.48}\n",
      "{'loss': 2.0481, 'learning_rate': 2.5401542936638424e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-4000\n",
      "Configuration saved in ./results\\checkpoint-4000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9954, 'learning_rate': 2.4769191855318073e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-4000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0307, 'learning_rate': 2.4136840773997723e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9881, 'learning_rate': 2.3504489692677376e-05, 'epoch': 0.53}\n",
      "{'loss': 1.9509, 'learning_rate': 2.287213861135703e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9076, 'learning_rate': 2.2239787530036675e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-4500\n",
      "Configuration saved in ./results\\checkpoint-4500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9406, 'learning_rate': 2.1607436448716328e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-4500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9384, 'learning_rate': 2.097508536739598e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9487, 'learning_rate': 2.034273428607563e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9556, 'learning_rate': 1.971038320475528e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9785, 'learning_rate': 1.9078032123434934e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-5000\n",
      "Configuration saved in ./results\\checkpoint-5000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0206, 'learning_rate': 1.8445681042114583e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-5000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9662, 'learning_rate': 1.7813329960794233e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9842, 'learning_rate': 1.7180978879473886e-05, 'epoch': 0.66}\n",
      "{'loss': 2.0086, 'learning_rate': 1.6548627798153535e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9608, 'learning_rate': 1.5916276716833185e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-5500\n",
      "Configuration saved in ./results\\checkpoint-5500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0461, 'learning_rate': 1.5283925635512838e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-5500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.965, 'learning_rate': 1.4651574554192488e-05, 'epoch': 0.71}\n",
      "{'loss': 2.0018, 'learning_rate': 1.4019223472872139e-05, 'epoch': 0.72}\n",
      "{'loss': 1.9851, 'learning_rate': 1.3386872391551792e-05, 'epoch': 0.73}\n",
      "{'loss': 1.9579, 'learning_rate': 1.275452131023144e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-6000\n",
      "Configuration saved in ./results\\checkpoint-6000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9575, 'learning_rate': 1.2122170228911093e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-6000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9087, 'learning_rate': 1.1489819147590743e-05, 'epoch': 0.77}\n",
      "{'loss': 2.0082, 'learning_rate': 1.0857468066270394e-05, 'epoch': 0.78}\n",
      "{'loss': 2.0013, 'learning_rate': 1.0225116984950045e-05, 'epoch': 0.8}\n",
      "{'loss': 2.008, 'learning_rate': 9.592765903629695e-06, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-6500\n",
      "Configuration saved in ./results\\checkpoint-6500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9353, 'learning_rate': 8.960414822309346e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-6500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9819, 'learning_rate': 8.328063740988997e-06, 'epoch': 0.83}\n",
      "{'loss': 1.9105, 'learning_rate': 7.695712659668649e-06, 'epoch': 0.85}\n",
      "{'loss': 1.9406, 'learning_rate': 7.0633615783482984e-06, 'epoch': 0.86}\n",
      "{'loss': 1.8958, 'learning_rate': 6.431010497027951e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-7000\n",
      "Configuration saved in ./results\\checkpoint-7000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9907, 'learning_rate': 5.798659415707601e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-7000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9228, 'learning_rate': 5.166308334387252e-06, 'epoch': 0.9}\n",
      "{'loss': 1.8919, 'learning_rate': 4.533957253066903e-06, 'epoch': 0.91}\n",
      "{'loss': 1.9164, 'learning_rate': 3.901606171746554e-06, 'epoch': 0.92}\n",
      "{'loss': 1.992, 'learning_rate': 3.269255090426205e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-7500\n",
      "Configuration saved in ./results\\checkpoint-7500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9206, 'learning_rate': 2.6369040091058556e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-7500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9883, 'learning_rate': 2.0045529277855064e-06, 'epoch': 0.96}\n",
      "{'loss': 1.9983, 'learning_rate': 1.3722018464651576e-06, 'epoch': 0.97}\n",
      "{'loss': 1.9633, 'learning_rate': 7.398507651448085e-07, 'epoch': 0.99}\n",
      "{'loss': 1.9329, 'learning_rate': 1.0749968382445935e-07, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 464.7978, 'train_samples_per_second': 17.033, 'train_steps_per_second': 17.033, 'train_loss': 2.0455152909834307, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7917, training_loss=2.0455152909834307, metrics={'train_runtime': 464.7978, 'train_samples_per_second': 17.033, 'train_steps_per_second': 17.033, 'train_loss': 2.0455152909834307, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n",
    "        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0] for f in data])}).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for title in test_titles: \n",
    "    new_titles = {\n",
    "        'seed': title.split()[0],\n",
    "        'predictions': []\n",
    "    }\n",
    "    generated = tokenizer(\"<|startoftext|> \"+ title.split()[0], return_tensors=\"pt\").input_ids.cuda()\n",
    "    sample_outputs = model.generate(generated,no_repeat_ngram_size = 1,num_beams=20, num_return_sequences=2)\n",
    "    \n",
    "    new_titles['predictions'] = sample_outputs\n",
    "    results.append(new_titles)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: When\n",
      "1:  When a young man falls in love with his girlfriend, he begins to suspect that she‚Äô\n",
      "2:  When a young man falls in love with his older sister, he's forced to choose between her\n",
      "seed: Ahead\n",
      "1:  Ahead of his first birthday, a young man embarks on an epic journey to find the truth\n",
      "2:  Ahead of his first birthday, a young man embarks on an epic journey to save the world\n",
      "seed: A\n",
      "1:  A young man's life is turned upside down when he falls in love with his best friend,\n",
      "2:  A young man's life is turned upside down when he falls in love with his ex-wife\n",
      "seed: This\n",
      "1:  This docuseries takes a look at the rise and fall of Donald Trump's presidential campaign,\n",
      "2:  This docuseries takes a look at the rise and fall of Donald Trump‚Äôs presidential\n",
      "seed: An\n",
      "1:  An ex-con returns to the U.S., where he reconnects with his estranged father\n",
      "2:  An ex-con returns to the U.S., where he meets his estranged wife, who\n",
      "seed: An\n",
      "1:  An ex-con returns to his hometown of New York, where he‚Äôs haunted by\n",
      "2:  An aspiring singer-songwriter falls in love with a young woman, but she soon finds herself\n",
      "seed: When\n",
      "1:  When a young man falls in love with the woman he loves, an ex-con tries to\n",
      "2:  When a young man falls in love with his best friend, he sets out to find the truth\n",
      "seed: In\n",
      "1:  In this stand-up special, three women from different backgrounds come together to share their stories of\n",
      "2:  In this stand-up special, three women from different backgrounds share stories about their experiences in the\n",
      "seed: In\n",
      "1:  In the aftermath of World War II, a young man's life is turned upside down when he\n",
      "2:  In the aftermath of World War II, a young man's life is turned upside down when his\n",
      "seed: When\n",
      "1:  When her father is murdered, a young woman embarks on an epic quest to uncover the truth\n",
      "2:  When her father is murdered, a young woman embarks on an epic quest to find the truth\n"
     ]
    }
   ],
   "source": [
    "for new_title in results:\n",
    "    print(f\"seed: {new_title['seed']}\")\n",
    "    for i, pred in enumerate(new_title['predictions']):\n",
    "        print(f\"{i+1}: {tokenizer.decode(pred, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tharhtet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46ff7e5b8b7911cfa9955e23e477c53e63d207f4b9ab3253a6a5ac7336ecbe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
